---
title: "2021101113_Reliability_Class_Activity"
author: "Gowlapalli Rohit"
date: "13/2/2024"
output:
  pdf_document:
    toc: true
  word_document:
    toc: true
  html_document: 
    toc:  
    toc_float: true 
---
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

# Advert Rating: Outlier Detection

```{r}
library(readxl)
data <- readxl::read_excel("BRSM_Assignment_Datasets.xlsx", sheet = 1)
print(data)
```
```{r}
library(reshape2)
library(ggplot2)
correlation_matrix <- round(cor(data), 2)
melted_correlation <- melt(correlation_matrix)
ggplot(data = melted_correlation, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = value), size = 2) +
  scale_fill_gradient2(low = "green", high = "black",
                       limit = c(-1, 1), name = "Pearson Correlation") +
  theme(axis.text.x = element_text(angle = 90))
```

```{r}
ratings <- data[, 1:26]
correlation_matrix <- cor(ratings)
heatmap(correlation_matrix, 
        symm = TRUE, 
        margins = c(12, 12),
        main = "Correlation Heatmap of Ratings")
```

```{r}
outlier <- which.min(apply(correlation_matrix, 1, function(x) sum(x)))
outlier_label <- LETTERS[outlier]
cat("Outlier participant:", outlier_label, "\n")
```
## Conclusion from the Correlation Heatmap

1. It's evident from the correlation heatmap that participants labeled A through Z, except for O, exhibit positive correlations between them as anticipated, indicating similar rating patterns.
   
2. However, for participant O, it's apparent that the correlations are consistently low, approaching zero in many instances. This suggests that participant O is an outlier, likely providing random ratings.


# Reliable Job: Internal Consistency

```{r}
library(psych)
data <- readxl::read_excel("BRSM_Assignment_Datasets.xlsx", sheet = 2)
js_items <- data[, c("JS1", "JS2", "JS3", "JS4")]
print(js_items)
jp_items <- data[, c("JP1", "JP2", "JP3", "JP4")]
print(jp_items)
```

```{r}
calculate_alpha <- function(items) {
  cor_matrix <- cor(items, method = "spearman")
  mean_corr <- mean(cor_matrix[lower.tri(cor_matrix)])
  num_items <- ncol(items)
  alpha <- (num_items * mean_corr) / (1 + (num_items - 1) * mean_corr)
  return(alpha)
}
```

```{r}
alpha_js <- calculate_alpha(js_items)
cat("Cronbach's Alpha for Job Satisfaction (JS):", alpha_js, "\n")
cat("For Job Satisfaction (JS):\n")
cat("Cronbach's Alpha:", alpha_js, "\n")
if (alpha_js >= 0.7) {
  cat("The internal consistency of the JS items is considered acceptable as Cronbach's Alpha is above 0.7.\n")
} else {
  cat("The internal consistency of the JS items is considered poor as Cronbach's Alpha is below 0.7.\n")

}
```

```{r}
alpha_jp <- calculate_alpha(jp_items)
cat("Cronbach's Alpha for Job Performance (JP):", alpha_jp, "\n")
cat("\nFor Job Performance (JP):\n")
cat("Cronbach's Alpha:", alpha_jp, "\n")
if (alpha_jp >= 0.7) {
  cat("The internal consistency of the JP items is considered acceptable as Cronbach's Alpha is above 0.7.\n")
} else {
  cat("The internal consistency of the JP items is considered poor as Cronbach's Alpha is below 0.7.\n")
}

```
## Conclusions from the Cronbach alpha for Job Performance and Job Satisfaction.
1. We know that the Cronbach alpha â‰¥ 0.7 is treated as acceptable for internal consistency.
2. In the case of Job Satisfaction, Cronbach alpha = 0.858. Hence, the measure of Job satisfaction is acceptable.
3. But in the case of Job Performance, Cronbach alpha = 0.524. Hence, the measure of Job Performance is not acceptable.

# Yulu: Normality Testing
```{r}
library(readxl)
df <- readxl::read_excel("BRSM_Assignment_Datasets.xlsx", sheet = 3)

datetime_column <- df$datetime
season_column <- df$season
holiday_column <- df$holiday
workingday_column <- df$workingday
weather_column <- df$weather
temp_column <- df$temp
atemp_column <- df$atemp
humidity_column <- df$humidity
windspeed_column <- df$windspeed
casual_column <- df$casual
registered_column <- df$registered
count_column <- df$count

summary(df)

hist(df$temp, main="Temperature Histogram", xlab="Temperature")
```
## Is there any effect of Working Day on the number of electric cycles rented ?
```{r}
# STEP-1 : Set up Null Hypothesis
# Null Hypothesis ( H0 ) - Working Day does not have any effect on the number of electric cycles rented.
# Alternate Hypothesis ( HA ) - Working Day has some effect on the number of electric cycles rented

# STEP-2 : Checking for basic assumptions for the hypothesis
# Distribution check using QQ Plot
# Homogeneity of Variances using Levene's test

# STEP-3: Define Test statistics; Distribution of T under H0.
# If the assumptions of T Test are met then we can proceed performing T Test for independent samples else we will perform the non-parametric test equivalent to T Test for independent sample i.e., Mann-Whitney U rank test for two independent samples.

# STEP-4: Compute the p-value and fix value of alpha.
# We set our alpha to be 0.05

# STEP-5: Compare p-value and alpha.
# Based on p-value, we will accept or reject H0.
# p-val > alpha : Accept H0
# p-val < alpha : Reject H0

# Visual Tests to know if the samples follow a normal distribution

library(ggplot2)
library(car)

# Visualizing descriptive statistics
workingday_descriptive <- df[df$workingday == 1, "count"]
non_workingday_descriptive <- df[df$workingday == 0, "count"]

ggplot(df, aes(x = factor(workingday), y = count)) +
  geom_boxplot() +
  labs(x = "Working Day", y = "Count") +
  ggtitle("Boxplot of Count based on Working Day")
```

```{r}
library(ggplot2)
library(car)
library(gridExtra)
workingday_descriptive <- df$count[df$workingday == 1]
non_workingday_descriptive <- df$count[df$workingday == 0]

hist_workingday <- ggplot(data = NULL, aes(x = workingday_descriptive)) +
  geom_histogram(fill = "green", color = "black", bins = 30, alpha = 0.5) +
  labs(title = "Histogram for Workingday", x = "Count", y = "Frequency") +
  theme_minimal()

hist_non_workingday <- ggplot(data = NULL, aes(x = non_workingday_descriptive)) +
  geom_histogram(fill = "blue", color = "black", bins = 30, alpha = 0.5) +
  labs(title = "Histogram for Non-workingday", x = "Count", y = "Frequency") +
  theme_minimal()

grid.arrange(hist_workingday, hist_non_workingday, ncol = 2)
```

```{r}
workingday_descriptive <- workingday_descriptive[!is.na(workingday_descriptive)]
qqPlot(workingday_descriptive, main = "QQ plot for workingday")
non_workingday_descriptive <- non_workingday_descriptive[!is.na(non_workingday_descriptive)]
qqPlot(non_workingday_descriptive, main = "QQ plot for non_workingday")
```


```{r}
workingday_descriptive_shapiro <- workingday_descriptive[1:5000]  
non_workingday_descriptive_shapiro <- non_workingday_descriptive[1:5000]
shapiro.test(workingday_descriptive_shapiro)
shapiro.test(non_workingday_descriptive_shapiro)
```
```{r}
library(MASS)
subset_workingday <- subset(df, workingday == 1)
transformed_workingday <- boxcox(count ~ 1, data = subset_workingday)$x
shapiro_test <- shapiro.test(transformed_workingday)
p_value <- shapiro_test$p.value
cat("p-value:", p_value, "\n")
if (p_value < 0.05) {
  cat("The sample does not follow normal distribution\n")
} else {
  cat("The sample follows normal distribution\n")
}
```


```{r}
library(MASS)
subset_non_workingday <- subset(df, workingday == 0)
transformed_non_workingday <- boxcox(count ~ 1, data = subset_non_workingday)$x
shapiro_test <- shapiro.test(transformed_non_workingday)
p_value <- shapiro_test$p.value
cat("p-value:", p_value, "\n")
if (p_value < 0.05) {
  cat("The sample does not follow normal distribution\n")
} else {
  cat("The sample follows normal distribution\n")
}
```


```{r}
# Null Hypothesis(H0) - Homogeneous Variance
# Alternate Hypothesis(HA) - Non-Homogeneous Variance
leveneTest(count ~ workingday, data = df)

# Ho : Mean no.of electric cycles rented is same for working and non-working days
# Ha : Mean no.of electric cycles rented is not the same for working and non-working days
# Assuming a significance Level to be 0.05
# Test statistics : Mann-Whitney U rank test for two independent samples

wilcox.test(count ~ workingday, data = df)
```





