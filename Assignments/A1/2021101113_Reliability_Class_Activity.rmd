---
title: "2021101113_Reliability_Class_Activity"
author: "Gowlapalli Rohit"
date: "20/2/2024"
output:
  pdf_document:
    toc: true
  html_document: 
    toc:  
    toc_float: true 
  word_document:
    toc: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```
# Advert Rating: Outlier Detection

```{r}
library(readxl)
data <- readxl::read_excel("BRSM_Assignment_Datasets.xlsx", sheet = 1)
print(data)
```

```{r}
library(reshape2)
library(ggplot2)
correlation_matrix <- round(cor(data), 2)
melted_correlation <- melt(correlation_matrix)
ggplot(data = melted_correlation, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  geom_text(aes(label = value), size = 2) +
  scale_fill_gradient2(low = "green", high = "black",
                       limit = c(-1, 1), name = "Pearson Correlation") +
  theme(axis.text.x = element_text(angle = 90))
```

```{r}
ratings <- data[, 1:26]
correlation_matrix <- cor(ratings)
heatmap(correlation_matrix, 
        symm = TRUE, 
        margins = c(2, 2),
        main = "Correlation Heatmap of Ratings")
```

```{r}
outlier <- which.min(apply(correlation_matrix, 1, function(x) sum(x)))
outlier_label <- LETTERS[outlier]
cat("Outlier participant:", outlier_label, "\n")
```
## Conclusion from the Correlation Heatmap

1. It's evident from the correlation heatmap that participants labeled A through Z, except for O, exhibit positive correlations between them as anticipated, indicating similar rating patterns.
   
2. However, for participant O, it's apparent that the correlations are consistently low, approaching zero in many instances. This suggests that participant O is an outlier, likely providing random ratings.


# Reliable Job: Internal Consistency

```{r}
library(psych)
data <- readxl::read_excel("BRSM_Assignment_Datasets.xlsx", sheet = 2)
js_items <- data[, c("JS1", "JS2", "JS3", "JS4")]
print(js_items)
jp_items <- data[, c("JP1", "JP2", "JP3", "JP4")]
print(jp_items)
```

```{r}
calculate_alpha <- function(items) {
  cor_matrix <- cor(items, method = "spearman")
  mean_corr <- mean(cor_matrix[lower.tri(cor_matrix)])
  num_items <- ncol(items)
  alpha <- (num_items * mean_corr) / (1 + (num_items - 1) * mean_corr)
  return(alpha)
}
```

```{r}
alpha_js <- calculate_alpha(js_items)
cat("Cronbach's Alpha for Job Satisfaction (JS):", alpha_js, "\n")
cat("For Job Satisfaction (JS):\n")
cat("Cronbach's Alpha:", alpha_js, "\n")
if (alpha_js >= 0.7) {
  cat("The internal consistency of the JS items is considered acceptable as Cronbach's Alpha is above 0.7.\n")
} else {
  cat("The internal consistency of the JS items is considered poor as Cronbach's Alpha is below 0.7.\n")

}
```

```{r}
alpha_jp <- calculate_alpha(jp_items)
cat("Cronbach's Alpha for Job Performance (JP):", alpha_jp, "\n")
cat("\nFor Job Performance (JP):\n")
cat("Cronbach's Alpha:", alpha_jp, "\n")
if (alpha_jp >= 0.7) {
  cat("The internal consistency of the JP items is considered acceptable as Cronbach's Alpha is above 0.7.\n")
} else {
  cat("The internal consistency of the JP items is considered poor as Cronbach's Alpha is below 0.7.\n")
}

```
## Conclusions from the Cronbach alpha for Job Performance and Job Satisfaction.
1. We know that the Cronbach alpha greater than 0.7 is treated as acceptable for internal consistency.
2. In the case of Job Satisfaction, Cronbach alpha = 0.858. Hence, the measure of Job satisfaction is acceptable
3. But in the case of Job Performance, Cronbach alpha = 0.524. Hence, the measure of Job Performance is not acceptable

Based on the calculated Cronbach’s alpha values for Job Satisfaction (JS) and Job Performance (JP):

- **Job Satisfaction (JS)** with a Cronbach’s Alpha of 0.8584497: This value exceeds the commonly accepted threshold of 0.7 for acceptable internal consistency, indicating excellent coherence among the items measuring job satisfaction. An alpha of approximately 0.858 suggests strong alignment and effective measurement of the same underlying construct within the Job Satisfaction scale. This high level of consistency implies reliability in assessing job satisfaction.

- **Job Performance (JP)** with a Cronbach’s Alpha of 0.5242351: This value falls below the commonly accepted threshold of 0.7 for acceptable internal consistency. An alpha of approximately 0.524 indicates inadequate coherence among the items measuring job performance. This suggests that the items within the Job Performance scale may not all effectively measure the same underlying construct, or there may be a lack of cohesion among them. It might be necessary to review and potentially revise the items in this scale to enhance its reliability. Potential adjustments could involve refining existing items or introducing new ones that better align with the overall construct of job performance.

#### Commentary on Internal Consistency and Acceptability:

- The Job Satisfaction measure showcases exceptional reliability and internal consistency, establishing it as a robust tool for evaluating job satisfaction. The elevated Cronbach’s alpha value signifies that the scale comprises items that effectively measure the construct of job satisfaction in unison, instilling confidence in its application for research or practical purposes.

- Conversely, the Job Performance measure demonstrates a level of reliability that falls below the acceptable standard, signaling a need for improvement. The diminished Cronbach’s alpha value implies that the scale could benefit from a comprehensive review of its items to ensure they collectively capture the intended construct of job performance. Enhancing the internal consistency of this scale is paramount for acquiring dependable and valid assessments of job performance.

#### Conclusion:

The analysis underscores a contrast in the reliability between the two scales. While the Job Satisfaction scale demonstrates exceptional reliability, establishing itself as a highly consistent and effective tool for gauging job satisfaction, the Job Performance scale necessitates substantial enhancements to attain an acceptable level of reliability. Initiatives aimed at refining the Job Performance scale should concentrate on elevating the Cronbach’s alpha value, ensuring that all items are pertinent and contribute positively to the assessment of job performance.

